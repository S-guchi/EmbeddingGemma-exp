{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77418e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from sentence_transformers import SentenceTransformer, losses, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if \"HUGGINGFACE_HUB_TOKEN\" in os.environ:\n",
    "    try:\n",
    "        login(token=os.environ[\"HUGGINGFACE_HUB_TOKEN\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "MODEL_ID = \"google/embeddinggemma-300m\"\n",
    "CSV_PATH = \"pairs.csv\"\n",
    "OUTPUT_DIR = \"ft-embeddinggemma\"\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "USE_AMP = torch.cuda.is_available()\n",
    "DEVICE  = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# ---- 居酒屋ドリンク予測データ読み込み ----\n",
    "# データ少ないから全部学習データにする\n",
    "train_df = pd.read_csv(CSV_PATH).drop_duplicates()\n",
    "\n",
    "train_samples = [\n",
    "    InputExample(texts=[r.query.strip(), r.item.strip()])\n",
    "    for r in train_df.itertuples(index=False)\n",
    "]\n",
    "# train_samples = [\n",
    "#     InputExample(texts=[\"唐揚げ\", \"ハイボール\"]),\n",
    "#     InputExample(texts=[\"枝豆\", \"ビール\"]),\n",
    "#     ...\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d094b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "BASE_BATCH_SIZE = 4\n",
    "# MAX_SEQ_LEN = 64\n",
    "# ---- Model ----\n",
    "model = SentenceTransformer(MODEL_ID, device=DEVICE)\n",
    "# model.max_seq_length = MAX_SEQ_LEN\n",
    "\n",
    "# ---- DataLoader ----\n",
    "BATCH_SIZE = min(BASE_BATCH_SIZE, max(1, len(train_samples)))\n",
    "train_loader = DataLoader(\n",
    "    train_samples,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# ---- Loss ----\n",
    "# バッチ内の正解以外をNegativeとして扱う\n",
    "# アンカー：「唐揚げ」\n",
    "# ポジティブ：「ハイボール」\n",
    "# ネガティブ：「枝豆」「冷奴」「レモンサワー」など\n",
    "# 唐揚げとハイボールの距離を近づけて、それ以外の距離を遠ざける指標\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "\n",
    "steps_per_epoch = max(1, len(train_loader))\n",
    "WARMUP_RATIO = 0.1\n",
    "warmup_steps = int(steps_per_epoch * EPOCHS * WARMUP_RATIO)\n",
    "\n",
    "# ---- 学習 ----\n",
    "model.fit(\n",
    "    train_objectives=[(train_loader, train_loss)],\n",
    "    epochs=EPOCHS,\n",
    "    warmup_steps=warmup_steps, # 学習率を徐々に上げていくスケジュール設定らしい\n",
    "    output_path=OUTPUT_DIR,\n",
    ")\n",
    "\n",
    "print(f\"✅ saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8e7c0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/purotoko/Project/EmbeddingGemma-exp/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:204: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v4 of SentenceTransformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Query: 唐揚げ\n",
      "Before:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.251  熱燗\n",
      "  0.232  焼酎\n",
      "  0.209  ビール\n",
      "  0.200  チューハイ\n",
      "  0.196  ホッピー\n",
      "After:\n",
      "  0.555  ハイボール\n",
      "  0.407  焼酎\n",
      "  0.380  チューハイ\n",
      "  0.349  ホッピー\n",
      "  0.321  泡盛\n",
      "\n",
      "### Query: チーズ唐揚げ\n",
      "Before:\n",
      "  0.213  チューハイ\n",
      "  0.200  ビール\n",
      "  0.195  焼酎\n",
      "  0.192  熱燗\n",
      "  0.176  生ビール\n",
      "After:\n",
      "  0.515  ハイボール\n",
      "  0.332  チューハイ\n",
      "  0.301  泡盛\n",
      "  0.296  ホッピー\n",
      "  0.295  焼酎\n"
     ]
    }
   ],
   "source": [
    "def rank(q, docs, m, topk=10):\n",
    "    import numpy as np\n",
    "    from numpy.linalg import norm\n",
    "    qv = m.encode_query(q)\n",
    "    dv = m.encode_document(docs)\n",
    "    sims = (qv @ dv.T) / (norm(qv) * norm(dv, axis=1))\n",
    "    order = np.argsort(-sims)[:topk]\n",
    "    return [(docs[i], float(sims[i])) for i in order]\n",
    "\n",
    "# CSVから「item（=ドリンク）」のユニーク集合を候補に\n",
    "corpus_texts = sorted(set(train_df[\"item\"].astype(str).tolist()))\n",
    "seen = set()\n",
    "demo_candidates = []\n",
    "for x in corpus_texts:\n",
    "    if x not in seen:\n",
    "        demo_candidates.append(x); seen.add(x)\n",
    "\n",
    "demo_queries = [\"唐揚げ\", \"チーズ唐揚げ\"]\n",
    "\n",
    "base = SentenceTransformer(MODEL_ID, device=DEVICE, use_auth_token=True)\n",
    "ft   = SentenceTransformer(OUTPUT_DIR, device=DEVICE)\n",
    "\n",
    "def show_demo(q):\n",
    "    print(f\"\\n### Query: {q}\")\n",
    "    print(\"Before:\")\n",
    "    for t, s in rank(q, demo_candidates, base, topk=5):\n",
    "        print(f\"  {s:.3f}  {t}\")\n",
    "    print(\"After:\")\n",
    "    for t, s in rank(q, demo_candidates, ft, topk=5):\n",
    "        print(f\"  {s:.3f}  {t}\")\n",
    "\n",
    "for q in demo_queries:\n",
    "    show_demo(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156c236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efc9b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
